import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import KFold
from sklearn.metrics import r2_score
from tqdm.notebook import tqdm
import warnings

warnings.filterwarnings("ignore")

# ==========================================
# 1. å‡†å¤‡æ•°æ®
# ==========================================
PATH = r"C:\Users\Administrator\GWRF"
FILE_NAME = "train_1211.xlsx"

try:
    df = pd.read_excel(f"{PATH}\\{FILE_NAME}")
except:
    print("âŒ è·¯å¾„é”™è¯¯")

# å®šä¹‰åˆ—
coord_cols = ['y_cordinat', 'x_cordinat']
target_col = 'Y'
group_col = 'Farm_ID'
feature_cols = [c for c in df.columns if c not in coord_cols + ['Y', 'Y_log', group_col, 'Status', 'Local_Imp']]

X = df[feature_cols]
y = df[target_col]
coords = df[coord_cols]

# ==========================================
# 2. æ ¸å¿ƒå‡½æ•°
# ==========================================
def calculate_weights(coords_all, target_point, bandwidth):
    lats = coords_all.iloc[:, 0].values
    lons = coords_all.iloc[:, 1].values
    t_lat, t_lon = target_point
    R = 6371000
    dlat = np.radians(lats - t_lat)
    dlon = np.radians(lons - t_lon)
    a = np.sin(dlat/2)**2 + np.cos(np.radians(t_lat)) * np.cos(np.radians(lats)) * np.sin(dlon/2)**2
    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))
    distances = R * c
    return np.exp(-0.5 * (distances / bandwidth) ** 2)

# ==========================================
# 3. å¸¦å®½ç½‘æ ¼æœç´¢ (Grid Search)
# ==========================================
# æœç´¢èŒƒå›´ï¼š5km åˆ° 50kmï¼Œæ­¥é•¿ 2.5km
BANDWIDTH_CANDIDATES = np.arange(5000, 50001, 2500)

results = []

print(f"ğŸš€ å¼€å§‹ä¸¥è°¨çš„å¸¦å®½å¯»ä¼˜ (æµ‹è¯• {len(BANDWIDTH_CANDIDATES)} ä¸ªå‚æ•°)...")

for bw in tqdm(BANDWIDTH_CANDIDATES):
    # ä½¿ç”¨ 5 æŠ˜äº¤å‰éªŒè¯æ¥è¯„ä¼°æ¯ä¸ªå¸¦å®½çš„è¡¨ç°
    # æ³¨æ„ï¼šä¸ºäº†é€Ÿåº¦ï¼Œè¿™é‡Œæˆ‘ä»¬åªæŠ½æ ·éªŒè¯ï¼Œæˆ–è€…åªè®¡ç®—æ‹Ÿåˆä¼˜åº¦ (AICc çš„ç®€åŒ–æ›¿ä»£)
    # è¿™é‡Œæˆ‘ä»¬ç”¨ Out-of-Bag (OOB) çš„æ€æƒ³ï¼šç›´æ¥çœ‹å±€éƒ¨æ¨¡å‹çš„ç¨³å®šæ€§
    
    valid_predictions = []
    valid_true = []
    nan_count = 0
    
    # ä¸ºäº†èŠ‚çœæ—¶é—´ï¼Œæˆ‘ä»¬éšæœºæŠ½æ · 200 ä¸ªç‚¹ä½œä¸ºæµ‹è¯•é›†ä»£è¡¨
    sample_indices = np.random.choice(len(X), size=200, replace=False)
    
    for i in sample_indices:
        target_pt = (coords.iloc[i, 0], coords.iloc[i, 1])
        w = calculate_weights(coords, target_pt, bandwidth=bw)
        
        # æƒé‡é˜ˆå€¼æ£€æŸ¥ (æœ‰æ•ˆæ ·æœ¬æ•°)
        if np.sum(w > 0.05) < 10:
            nan_count += 1
            continue
            
        try:
            # è®­ç»ƒè½»é‡çº§å±€éƒ¨æ¨¡å‹
            lrf = RandomForestRegressor(n_estimators=30, max_depth=5, n_jobs=1, random_state=42)
            # ä½¿ç”¨æ‰€æœ‰æ•°æ®åŠ æƒè®­ç»ƒ
            lrf.fit(X, y, sample_weight=w)
            
            # é¢„æµ‹è‡ªå·± (è¿‘ä¼¼è®­ç»ƒè¯¯å·®ï¼Œç”¨äºè¯„ä¼°æ”¶æ•›æ€§)
            pred = lrf.predict(X.iloc[[i]])[0]
            
            valid_predictions.append(pred)
            valid_true.append(y.iloc[i])
            
        except:
            nan_count += 1
            
    # è®¡ç®—è¯¥å¸¦å®½ä¸‹çš„æŒ‡æ ‡
    if len(valid_predictions) > 10:
        score = r2_score(valid_true, valid_predictions)
    else:
        score = -999
        
    validity_rate = 1 - (nan_count / 200) # æœ‰æ•ˆç‡
    
    results.append({
        'Bandwidth': bw,
        'R2': score,
        'Validity': validity_rate
    })

# ==========================================
# 4. ç»“æœå¯è§†åŒ–ä¸æœ€ä¼˜é€‰æ‹©
# ==========================================
res_df = pd.DataFrame(results)

# æ‰¾åˆ° R2 æœ€é«˜ ä¸” Validity > 0.8 (è‡³å°‘80%çš„ç‚¹èƒ½ç®—å‡ºæ¥) çš„å¸¦å®½
best_row = res_df[res_df['Validity'] > 0.8].sort_values('R2', ascending=False).iloc[0]
best_bw = int(best_row['Bandwidth'])

print(f"\nğŸ† ç»Ÿè®¡å­¦æœ€ä¼˜å¸¦å®½: {best_bw} m")
print(f"   (R2={best_row['R2']:.4f}, æœ‰æ•ˆæ ·æœ¬ç‡={best_row['Validity']:.1%})")

# ç”»å›¾
fig, ax1 = plt.subplots(figsize=(10, 6))

color = 'tab:blue'
ax1.set_xlabel('Bandwidth (m)')
ax1.set_ylabel('Model RÂ² (Accuracy)', color=color)
ax1.plot(res_df['Bandwidth'], res_df['R2'], marker='o', color=color, label='RÂ² Score')
ax1.tick_params(axis='y', labelcolor=color)
ax1.grid(True, alpha=0.3)

ax2 = ax1.twinx()  # åŒåæ ‡è½´
color = 'tab:red'
ax2.set_ylabel('Validity Rate (Points without NaN)', color=color)
ax2.plot(res_df['Bandwidth'], res_df['Validity'], marker='x', linestyle='--', color=color, label='Validity')
ax2.tick_params(axis='y', labelcolor=color)

# æ ‡å‡ºæœ€ä¼˜çº¿
plt.axvline(best_bw, color='green', linestyle='-', linewidth=2, label=f'Optimal: {best_bw}m')

plt.title("Bandwidth Optimization: Trade-off between Accuracy and Coverage")
fig.tight_layout()
plt.show()

print("\nğŸ’¡ å†³ç­–å»ºè®®ï¼š")
print("1. è“çº¿ (RÂ²) åº”è¯¥ä¼šå‘ˆç°å…ˆä¸Šå‡åä¸‹é™ï¼ˆæˆ–è¶‹äºå¹³ç¨³ï¼‰çš„è¶‹åŠ¿ã€‚")
print("2. çº¢çº¿ (Validity) ä¼šéšç€å¸¦å®½å¢åŠ è€Œä¸Šå‡ï¼Œç›´åˆ° 1.0ã€‚")
print("3. æˆ‘ä»¬é€‰çš„é‚£ä¸ªç‚¹ï¼Œæ˜¯çº¢çº¿è¶³å¤Ÿé«˜ï¼Œä¸”è“çº¿å¤„äºå³°å€¼çš„ä½ç½®ã€‚")
print("è¿™å°±æ˜¯ä½ å¦å®š 10kmï¼Œæ”¹ç”¨æ–°å¸¦å®½çš„é“è¯ã€‚")
